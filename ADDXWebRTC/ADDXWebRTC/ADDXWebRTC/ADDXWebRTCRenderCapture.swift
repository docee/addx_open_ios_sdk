//
//  ADDXWebRTCRenderCapture.swift
//  ADAutoView
//
//  Created by Hao Shen on 6/30/20.
//

import Foundation
import UIKit
import WebRTC

#if arch(arm64)
class ADDXWebRTCRenderCapture: RTCMTLVideoView {
    let videoCapture = WebRTCVideoCapture.init()
    var captureImage = false
    var captureVideo = false
    var videoSize = Size.init(width: 0, height: 0)
    var lastFrameTime:Int64 = 0
    var grabImageDataFinishBlock: (() -> ())?
    var frameIndex: Int64 = -1
    var lastframeIndex: Int64 = -1
    
    var renderFirstFrameBlock : (()->Void)?
    
    func resetRender() {
        frameIndex = -1
        lastframeIndex = -1
    }
    
    func isRendering() -> Bool {
        if self.frameIndex < 0 {
            return false
        }
        if self.frameIndex > self.lastFrameTime {
            self.lastFrameTime = self.frameIndex
            return true
        }
        return false
    }
    
    func startCaptureImage(_ grabImageDataFinishCallback:(() -> Void)? = nil,_ completionCallback:((_ image: UIImage) -> Void)? = nil){
        self.grabImageDataFinishBlock = nil
        self.grabImageDataFinishBlock = grabImageDataFinishCallback
        self.startCaptureImage(completionCallback)
    }
    
    // å¼€å§‹æˆªå±
    func startCaptureImage(_ completionCallback:((_ image: UIImage) -> Void)? = nil){
        if self.captureImage {
            self.grabImageDataFinishBlock = nil
            return
        }
        self.videoCapture.captureImageFinishBlock = completionCallback
        self.captureImage = true
    }
    
    //å°†è§£ç è§†é¢‘å¸§ç¼–ç mp4
    func startCaptureVideo(path: URL) -> Bool{
        if self.videoSize.width * self.videoSize.width <= 0 {
            Log.vLog(level: .warning, "Render è§†é¢‘å°ºå¯¸æœªçŸ¥")
            return false
        }
        var sucess = true
        sucess = self.videoCapture.configCaptureVideoInfo(url: path, size: self.videoSize)
        if sucess {
           sucess = self.videoCapture.startVideoCapture()
        }else{
            Log.vLog(level: .warning, "Render é…ç½®ç¼–ç å™¨å¤±è´¥")
        }
        if sucess {
            self.captureVideo = true
        }else{
            Log.vLog(level: .error, "Render å¯åŠ¨å½•åˆ¶å¤±è´¥")
        }
        
        return sucess
    }
    func stopCaptureVideo(_ completionCallback:((_ sucess: Bool, _ fileUrl:URL?) -> Void)? = nil){
        self.captureVideo = false
        self.videoCapture.stopVideoCapture { (suceess, url) in
            Log.vLog(level: .notice, "Render ä¿å­˜è§†é¢‘å®Œæˆ")
            completionCallback?(suceess,url)
        }
    }
    //å°†h264è§†é¢‘æµä¿å­˜h264æ–‡ä»¶ï¼Œ
    func startCaptureH264Video(path: URL) -> Bool{
        if self.videoSize.width * self.videoSize.width <= 0 {
            Log.vLog(level: .warning, "Render è§†é¢‘å°ºå¯¸æœªçŸ¥")
            return false
        }
        var sucess = true
        sucess = self.videoCapture.startH264VideoCapture(url: path)
        if sucess {
           sucess = self.videoCapture.startVideoCapture()
        }else{
            Log.vLog(level: .error, "Render é…ç½®ç¼–ç å™¨å¤±è´¥")
        }
        if sucess {
            self.captureVideo = true
        }else{
            Log.vLog(level: .error, "Render å¯åŠ¨å½•åˆ¶å¤±è´¥")
        }
        
        return sucess
    }
    func stopCaptureH264Video(_ completionCallback:((_ firstFrameTime: Int64, _ fileUrl:URL?) -> Void)? = nil){
        self.captureVideo = false
        self.videoCapture.stopH264VideoCapture { (firstFrameTime, url) in
            Log.vLog(level: .notice, "Render ä¿å­˜è§†é¢‘å®Œæˆ")
            completionCallback?(firstFrameTime,url)
        }
    }
    override func setSize(_ size: CGSize) {
        self.videoSize = Size.init(width: Float(size.width), height: Float(size.height))
    }
    
    override func renderFrame(_ frame: RTCVideoFrame?) {
        self.frameIndex = self.frameIndex + 1
        if self.frameIndex == 1 {
            // ç›´æ’­æ‹¿åˆ°é¦–å¸§
            debugPrint("-----------> renderFrame1 func ç›´æ’­æ‹¿åˆ°é¦–å¸§")
            Log.vLog(level: .alert, "renderFrame func first alert2 ðŸ’šâ¤ï¸ step14-2")
            renderFirstFrameBlock?()
        }
        
        if self.captureImage {
            self.captureImage = false
            if frame != nil {
                self.grabImageDataFinishBlock?()
                self.grabImageDataFinishBlock = nil
                self.videoSize = Size.init(width: Float(frame!.width), height: Float(frame!.height))
                self.videoCapture.captureImage(frame: frame!)
            } else {
                Log.vLog(level: .error, "Render å¾…æˆªå–æˆå›¾ç‰‡çš„å¸§ä¸ºç©º")
            }
        }else if self.captureVideo {
            //æš‚æ—¶ä¸é€šè¿‡æ­¤ç§æ–¹å¼å½•åƒ, è€Œæ˜¯é€šè¿‡processEncodeå›žè°ƒç¼–ç æµå½•åƒ
            //hevcç¼–ç æ–¹å¼ä¸‹encodeFrameä¼šå¯¼è‡´appæ’­æ”¾å¡ä½1-2sec
            /*
            if frame != nil {
                self.videoSize = Size.init(width: Float(frame!.width), height: Float(frame!.height))
                self.videoCapture.encodeFrame(frame: frame!)
            } else {
                Log.vLog(level: .error, "Render å¾…ç¼–ç å¸§ä¸ºç©º")
            }
            */
        }
    }
    override func needProcessEncodeImage() -> Bool {
        return self.captureVideo
    }
    override func processEncode(_ image: RTCEncodedImage?) {
        if image == nil {
            return
        }
        self.videoCapture.writeH264Image(image: image!)
    }
}
#else
class ADDXWebRTCRenderCapture: RTCEAGLVideoView {
    let videoCapture = WebRTCVideoCapture.init()
    var captureImage = false
    var captureVideo = false
    var videoSize = Size.init(width: 0, height: 0)
    var lastFrameTime:Int64 = 0
    var grabImageDataFinishBlock: (() -> ())?
    var frameIndex: Int64 = -1
    var lastframeIndex: Int64 = -1
    
    
    var renderFirstFrameBlock : (()->Void)?
    
    func resetRender() {
        frameIndex = -1
        lastframeIndex = -1
    }
    
    
    func isRendering() -> Bool {
        if self.frameIndex < 0 {
            return false
        }
        if self.frameIndex > self.lastFrameTime {
            self.lastFrameTime = self.frameIndex
            return true
        }
        return false
    }
    
    func startCaptureImage(_ grabImageDataFinishCallback:(() -> Void)? = nil,_ completionCallback:((_ image: UIImage) -> Void)? = nil){
        self.grabImageDataFinishBlock = nil
        self.grabImageDataFinishBlock = grabImageDataFinishCallback
        self.startCaptureImage(completionCallback)
    }
    
    // å¼€å§‹æˆªå±
    func startCaptureImage(_ completionCallback:((_ image: UIImage) -> Void)? = nil){
        if self.captureImage {
            self.grabImageDataFinishBlock = nil
            return
        }
        self.videoCapture.captureImageFinishBlock = completionCallback
        self.captureImage = true
    }
    
    //å°†è§£ç è§†é¢‘å¸§ç¼–ç mp4
    func startCaptureVideo(path: URL) -> Bool{
        if self.videoSize.width * self.videoSize.width <= 0 {
            Log.vLog(level: .warning, "Render è§†é¢‘å°ºå¯¸æœªçŸ¥")
            return false
        }
        var sucess = true
        sucess = self.videoCapture.configCaptureVideoInfo(url: path, size: self.videoSize)
        if sucess {
           sucess = self.videoCapture.startVideoCapture()
        }else{
            Log.vLog(level: .error, "Render é…ç½®ç¼–ç å™¨å¤±è´¥")
        }
        if sucess {
            self.captureVideo = true
        }else{
            Log.vLog(level: .error, "Render å¯åŠ¨å½•åˆ¶å¤±è´¥")
        }
        
        return sucess
    }
    
    func stopCaptureVideo(_ completionCallback:((_ sucess: Bool, _ fileUrl:URL?) -> Void)? = nil){
        self.captureVideo = false
        self.videoCapture.stopVideoCapture { (suceess, url) in
            Log.vLog(level: .notice, "Render ä¿å­˜è§†é¢‘å®Œæˆ")
            completionCallback?(suceess,url)
        }
    }
    
    //å°†h264è§†é¢‘æµä¿å­˜h264æ–‡ä»¶ï¼Œ
    func startCaptureH264Video(path: URL) -> Bool{
        if self.videoSize.width * self.videoSize.width <= 0 {
            Log.vLog(level: .warning, "Render è§†é¢‘å°ºå¯¸æœªçŸ¥")
            return false
        }
        var sucess = true
        sucess = self.videoCapture.startH264VideoCapture(url: path)
        if sucess {
            self.captureVideo = true
        }else{
            Log.vLog(level: .error, "Render å¯åŠ¨å½•åˆ¶å¤±è´¥")
        }
        
        return sucess
    }
    
    func stopCaptureH264Video(_ completionCallback:((_ firstFrameTime: Int64, _ fileUrl:URL?) -> Void)? = nil){
        self.captureVideo = false
        self.videoCapture.stopH264VideoCapture { (firstFrameTime, url) in
            Log.vLog(level: .notice, "Render ä¿å­˜è§†é¢‘å®Œæˆ")
            completionCallback?(firstFrameTime,url)
        }
    }
    
    override func setSize(_ size: CGSize) {
        self.videoSize = Size.init(width: Float(size.width), height: Float(size.height))
    }
    
    override func renderFrame(_ frame: RTCVideoFrame?) {
        if frame == nil {
            return
        }
        
        if self.lastFrameTime == frame!.timeStampNs {
            return
        }
        
        self.frameIndex = self.frameIndex + 1
        if self.frameIndex == 1 {
            // ç›´æ’­æ‹¿åˆ°é¦–å¸§
            debugPrint("-----------> renderFrame2 func ç›´æ’­æ‹¿åˆ°é¦–å¸§")
            renderFirstFrameBlock?()
            Log.vLog(level: .alert, "renderFrame func first alert1 ðŸ’šâ¤ï¸ step14-2")
        }
        self.lastFrameTime = frame!.timeStampNs

        if self.captureImage {
            self.captureImage = false
            self.grabImageDataFinishBlock?()
            self.grabImageDataFinishBlock = nil
            self.videoSize = Size.init(width: Float(frame!.width), height: Float(frame!.height))
            self.videoCapture.captureImage(frame: frame!)
            
        }else if self.captureVideo {
            self.videoSize = Size.init(width: Float(frame!.width), height: Float(frame!.height))
            self.videoCapture.encodeFrame(frame: frame!)
            
        }
    }
    
    override func needProcessEncodeImage() -> Bool {
        return self.captureVideo
    }
    
    override func processEncode(_ image: RTCEncodedImage?) {
        if image == nil {
            return
        }
        self.videoCapture.writeH264Image(image: image!)
    }
}

#endif

class ADDXWebRTCMediaProcess: NSObject {
    class func  mergeAudio(audioURL: URL, audioFirstFrameTime:CMTime , moviePathUrl: URL, movieFirstFrameTime: CMTime,_ completionCallback:((_ sucess: Bool) -> Void)? = nil) {
        var savePathUrl = moviePathUrl.deletingLastPathComponent()
        savePathUrl = savePathUrl.appendingPathComponent("tempTest")
        savePathUrl = savePathUrl.appendingPathExtension(moviePathUrl.pathExtension)
        let composition = AVMutableComposition()
        let trackVideo:AVMutableCompositionTrack = composition.addMutableTrack(withMediaType: AVMediaType.video, preferredTrackID: CMPersistentTrackID())!
        let trackAudio:AVMutableCompositionTrack = composition.addMutableTrack(withMediaType: AVMediaType.audio, preferredTrackID: CMPersistentTrackID())!
        
        let videoAsset = AVURLAsset(url: moviePathUrl, options: nil)
        let audioAsset = AVURLAsset(url: audioURL, options: nil)

        let videos = videoAsset.tracks(withMediaType: AVMediaType.video)
        let audios = audioAsset.tracks(withMediaType: AVMediaType.audio)

        if videos.count > 0 && audios.count > 0{
            let assetTrackVideo:AVAssetTrack = videos[0]
            let assetTrackAudio:AVAssetTrack = audios[0]
            let audioDuration:CMTime = assetTrackAudio.timeRange.duration
            let audioStart:CMTime = audioFirstFrameTime
            let audioEnd:CMTime = CMTimeAdd(audioStart, audioDuration)

            let videoDuration:CMTime = assetTrackVideo.timeRange.duration
            let videoStart:CMTime = movieFirstFrameTime
            let videoEnd:CMTime = CMTimeAdd(videoStart, videoDuration)

            let mediaStart:CMTime = CMTimeMaximum(audioStart, videoStart)
            let mediaEnd:CMTime = CMTimeMinimum(audioEnd, videoEnd)
            
            let mediaCropDuration = CMTimeSubtract(mediaEnd, mediaStart)
            var audioCropDuration = mediaCropDuration
            var videoCropDuration = mediaCropDuration
            var audioCropStart = CMTimeSubtract(mediaStart, audioStart)
            var videoCropStart = CMTimeSubtract(mediaStart, videoStart)
            
            do {
                Log.vLog(level: .notice, "Render ADDXWebRTCMediaProcess crop compute video track crop start \(videoCropStart)   duration \(videoCropDuration)")
                
                if videoCropStart.seconds < 0 || videoCropStart.seconds >= videoDuration.seconds || videoCropDuration.seconds > videoDuration.seconds || videoCropDuration.seconds <= 0 {
                    videoCropStart = CMTime.zero
                    videoCropDuration = videoDuration
                }
                
                Log.vLog(level: .notice, "Render ADDXWebRTCMediaProcess video track real crop start \(videoCropStart)   duration \(videoCropDuration)")
                try  trackVideo.insertTimeRange(CMTimeRangeMake(start: videoCropStart, duration: videoCropDuration), of: assetTrackVideo, at: CMTime.zero)
            } catch  {

            }
            
            do {
                Log.vLog(level: .notice, "Render ADDXWebRTCMediaProcess crop compute audio track crop start \(audioCropStart)   duration \(audioCropDuration)")

                if audioCropStart.seconds < 0 || audioCropStart.seconds >= audioDuration.seconds || audioCropDuration.seconds > audioDuration.seconds || audioCropDuration.seconds <= 0 {
                    audioCropStart = CMTime.zero
                    audioCropDuration = audioDuration
                }
                Log.vLog(level: .notice, "Render ADDXWebRTCMediaProcess audio track  real crop start \(audioCropStart)   duration \(audioCropDuration)")
                try trackAudio.insertTimeRange(CMTimeRangeMake(start: audioCropStart, duration: audioCropDuration), of: assetTrackAudio, at: CMTime.zero)
            } catch  {

            }
        }
        let assetExport: AVAssetExportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetPassthrough)!
        var type = AVFileType.mp4
        if moviePathUrl.path.hasSuffix("mov") {
            type = AVFileType.mov
        }
        assetExport.outputFileType = type
        assetExport.outputURL = savePathUrl
        assetExport.shouldOptimizeForNetworkUse = true
        assetExport.exportAsynchronously {
            switch assetExport.status {
            case AVAssetExportSession.Status.completed:
                do {
                    try FileManager.default.removeItem(atPath: moviePathUrl.path)
                } catch  {
                    Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess åˆ é™¤æ–‡ä»¶å¤±è´¥  \(moviePathUrl)")
                }
                do {
                    try FileManager.default.removeItem(atPath: audioURL.path)
                } catch  {
                    Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess åˆ é™¤æ–‡ä»¶å¤±è´¥  \(audioURL)")
                }
                do {
                    try  FileManager.default.moveItem(at: savePathUrl, to: moviePathUrl)

                } catch  {
                    Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess ç§»åŠ¨æ–‡ä»¶å¤±è´¥  \(savePathUrl) to \(moviePathUrl)")
                }
                Log.vLog(level: .notice, "Render ADDXWebRTCMediaProcess success")
                do {
                    try FileManager.default.removeItem(atPath: savePathUrl.path)
                } catch  {
                    Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess åˆ é™¤æ–‡ä»¶å¤±è´¥  \(savePathUrl)")
                }
                completionCallback?(true)
                break
            case  AVAssetExportSession.Status.exporting:
                Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess exporting ---- \(String(describing: assetExport.error))")
                break
            case  AVAssetExportSession.Status.failed:
                Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess failed ---- \(String(describing: assetExport.error))")
                completionCallback?(false)
                break
            case AVAssetExportSession.Status.cancelled:
                Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess cancelled ---- \(String(describing: assetExport.error))")
                completionCallback?(false)
                break
            default:
                Log.vLog(level: .error, "Render ADDXWebRTCMediaProcess unknow error -----")
                completionCallback?(false)
                break
            }
            
        }
    }

}
